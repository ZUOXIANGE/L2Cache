# L2Cache 高级特性

## 1. 并发控制与锁机制

在极高并发场景下，缓存系统面临两大挑战：**缓存击穿 (Cache Stampede)** 和 **并发写入冲突**。L2Cache 内置了多级锁机制来解决这些问题。

### 1.1 缓存击穿保护

当一个热点 Key 过期时，如果同时有成千上万的请求涌入，它们可能会同时发现缓存失效，然后同时去查询数据库，瞬间击垮数据库。

L2Cache 采用了 **Double-Checked Locking (双重检查锁)** 模式：

1.  **检查 L1/L2 缓存**：如果存在，直接返回。
2.  **获取锁**：如果不存在，尝试获取锁（先内存锁，后分布式锁）。
3.  **再次检查缓存**：获取锁后，再次检查缓存（可能别的线程已经加载好了）。
4.  **回源加载**：如果还是没有，才真正去查询数据库。
5.  **写入缓存并释放锁**。

### 1.2 锁的类型

-   **内存锁 (Memory Lock)**: 使用 `SemaphoreSlim` 实现。
    -   **作用**: 限制单机内只有一个线程能去加载同一个 Key。
    -   **性能**: 极高，无网络开销。
    -   **局限**: 无法限制多实例/多节点间的并发。

-   **分布式锁 (Distributed Lock)**: 使用 Redis `SET NX` 实现。
    -   **作用**: 限制整个集群内只有一个实例能去加载同一个 Key。
    -   **性能**: 依赖 Redis 网络往返，略低于内存锁。
    -   **互补**: L2Cache 默认先抢内存锁，抢到的那个线程再去抢分布式锁，从而将集群级别的竞争降低到单机级别的竞争，极大减少了 Redis 的锁争用压力。

### 1.3 启用方式

请参考 [配置指南](Configuration-Guide.md#6-并发锁配置-lock-options)。

## 2. 批量操作优化

L2Cache 针对批量场景（如列表页加载）进行了深度优化。

### 2.1 批量获取 (BatchGet)

使用 Redis `MGET` 命令一次性获取多个 Key，大幅减少网络 RTT。

### 2.2 批量回源与僵尸缓存防御

`BatchGetOrLoadAsync` 实现了智能的批量回源逻辑：

1.  **批量查询缓存**：先尝试从 L1/L2 批量获取。
2.  **计算缺失 Key**：找出未命中的 Key。
3.  **批量回源**：调用用户实现的 `QueryDataListAsync` 一次性从 DB 加载。
4.  **安全回填 (Anti-Zombie)**：
    -   在将 DB 数据回填到缓存之前，L2Cache 会对每个 Key 进行**版本/存在性检查**。
    -   如果在此期间有并发的 `PutAsync` 更新了某个 Key，批量回填逻辑会**放弃**覆盖该 Key，从而避免将旧数据覆盖新数据（僵尸缓存问题）。

## 3. 缓存一致性保障

L2Cache 遵循 **Cache Aside** 模式，并提供以下机制保障一致性：

-   **更新策略**: `PutAsync` 会同时更新 L1 和 L2。
-   **淘汰策略**: `EvictAsync` 会同时删除 L1 和 L2。
-   **自动过期**: 支持 TTL (Time To Live)。
-   **被动更新**: 依赖 Redis Pub/Sub（未来规划）或被动过期来同步多级缓存。
-   **强制刷新**: `ReloadAsync` 强制回源并更新缓存。
